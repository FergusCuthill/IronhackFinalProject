{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# customisations - ensure tables show all columns\n",
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(url, parameters=None):\n",
    "    \"\"\"Return json-formatted response of a get request using optional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "    parameters : {'parameter': 'value'}\n",
    "        parameters to pass as part of get request\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    json_data\n",
    "        json-formatted response (dict-like)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url=url, params=parameters)\n",
    "    except SSLError as s:\n",
    "        print('SSL Error:', s)\n",
    "        \n",
    "        for i in range(5, 0, -1):\n",
    "            print('\\rWaiting... ({})'.format(i), end='')\n",
    "            time.sleep(1)\n",
    "        print('\\rRetrying.' + ' '*10)\n",
    "        \n",
    "        # recusively try again\n",
    "        return get_request(url, parameters)\n",
    "    \n",
    "    if response:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # response is none usually means too many requests. Wait and try again \n",
    "        print('No response, waiting 10 seconds...')\n",
    "        time.sleep(10)\n",
    "        print('Retrying.')\n",
    "        return get_request(url, parameters)\n",
    "\n",
    "def get_app_data(start, stop, parser, pause):\n",
    "    \"\"\"Return list of app data generated from parser.\n",
    "    \n",
    "    parser : function to handle request\n",
    "    \"\"\"\n",
    "    app_data = []\n",
    "    \n",
    "    # iterate through each row of app_list, confined by start and stop\n",
    "    for index, row in app_list[start:stop].iterrows():\n",
    "        print('Current index: {}'.format(index), end='\\r')\n",
    "        \n",
    "        appid = row['appid']\n",
    "        name = row['name']\n",
    "\n",
    "        # retrive app data for a row, handled by supplied parser, and append to list\n",
    "        data = parser(appid, name)\n",
    "        app_data.append(data)\n",
    "\n",
    "        time.sleep(pause) # prevent overloading api with requests\n",
    "    \n",
    "    return app_data\n",
    "\n",
    "\n",
    "def process_batches(parser, app_list, download_path, data_filename, index_filename,\n",
    "                    columns, begin=0, end=-1, batchsize=100, pause=1):\n",
    "    \"\"\"Process app data in batches, writing directly to file.\n",
    "    \n",
    "    parser : custom function to format request\n",
    "    app_list : dataframe of appid and name\n",
    "    download_path : path to store data\n",
    "    data_filename : filename to save app data\n",
    "    index_filename : filename to store highest index written\n",
    "    columns : column names for file\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    begin : starting index (get from index_filename, default 0)\n",
    "    end : index to finish (defaults to end of app_list)\n",
    "    batchsize : number of apps to write in each batch (default 100)\n",
    "    pause : time to wait after each api request (defualt 1)\n",
    "    \n",
    "    returns: none\n",
    "    \"\"\"\n",
    "    print('Starting at index {}:\\n'.format(begin))\n",
    "    \n",
    "    # by default, process all apps in app_list\n",
    "    if end == -1:\n",
    "        end = len(app_list) + 1\n",
    "    \n",
    "    # generate array of batch begin and end points\n",
    "    batches = np.arange(begin, end, batchsize)\n",
    "    batches = np.append(batches, end)\n",
    "    \n",
    "    apps_written = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    for i in range(len(batches) - 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = batches[i]\n",
    "        stop = batches[i+1]\n",
    "        \n",
    "        app_data = get_app_data(start, stop, parser, pause)\n",
    "        \n",
    "        rel_path = os.path.join(download_path, data_filename)\n",
    "        \n",
    "        # writing app data to file\n",
    "        with open(rel_path, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns, extrasaction='ignore')\n",
    "            \n",
    "            for j in range(3,0,-1):\n",
    "                print(\"\\rAbout to write data, don't stop script! ({})\".format(j), end='')\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            writer.writerows(app_data)\n",
    "            print('\\rExported lines {}-{} to {}.'.format(start, stop-1, data_filename), end=' ')\n",
    "            \n",
    "        apps_written += len(app_data)\n",
    "        \n",
    "        idx_path = os.path.join(download_path, index_filename)\n",
    "        \n",
    "        # writing last index to file\n",
    "        with open(idx_path, 'w') as f:\n",
    "            index = stop\n",
    "            print(index, file=f)\n",
    "            \n",
    "        # logging time taken\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        \n",
    "        batch_times.append(time_taken)\n",
    "        mean_time = statistics.mean(batch_times)\n",
    "        \n",
    "        est_remaining = (len(batches) - i - 2) * mean_time\n",
    "        \n",
    "        remaining_td = dt.timedelta(seconds=round(est_remaining))\n",
    "        time_td = dt.timedelta(seconds=round(time_taken))\n",
    "        mean_td = dt.timedelta(seconds=round(mean_time))\n",
    "        \n",
    "        print('Batch {} time: {} (avg: {}, remaining: {})'.format(i, time_td, mean_td, remaining_td))\n",
    "            \n",
    "    print('\\nProcessing batches complete. {} apps written'.format(apps_written))\n",
    "\n",
    "    \n",
    "def reset_index(download_path, index_filename):\n",
    "    \"\"\"Reset index in file to 0.\"\"\"\n",
    "    rel_path = os.path.join(download_path, index_filename)\n",
    "    \n",
    "    with open(rel_path, 'w') as f:\n",
    "        print(0, file=f)\n",
    "        \n",
    "\n",
    "def get_index(download_path, index_filename):\n",
    "    \"\"\"Retrieve index from file, returning 0 if file not found.\"\"\"\n",
    "    try:\n",
    "        rel_path = os.path.join(download_path, index_filename)\n",
    "\n",
    "        with open(rel_path, 'r') as f:\n",
    "            index = int(f.readline())\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        index = 0\n",
    "        \n",
    "    return index\n",
    "\n",
    "\n",
    "def prepare_data_file(download_path, filename, index, columns):\n",
    "    \"\"\"Create file and write headers if index is 0.\"\"\"\n",
    "    if index == 0:\n",
    "        rel_path = os.path.join(download_path, filename)\n",
    "\n",
    "        with open(rel_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            \n",
    "def parse_steam_request(appid, name):\n",
    "    \"\"\"Unique parser to handle data from Steam Store API.\n",
    "    \n",
    "    Returns : json formatted data (dict-like)\n",
    "    \"\"\"\n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    json_app_data = json_data[str(appid)]\n",
    "    \n",
    "    if json_app_data['success']:\n",
    "        data = json_app_data['data']\n",
    "    else:\n",
    "        data = {'name': name, 'steam_appid': appid}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_steamspy_request(appid, name):\n",
    "    \"\"\"Parser to handle SteamSpy API data.\"\"\"\n",
    "    url = \"https://steamspy.com/api.php\"\n",
    "    parameters = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid                       name\n",
       "0     10             Counter-Strike\n",
       "1     20      Team Fortress Classic\n",
       "2     30              Day of Defeat\n",
       "3     40         Deathmatch Classic\n",
       "4     50  Half-Life: Opposing Force"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather IDs and game names from SteamSpy\n",
    "url = \"https://steamspy.com/api.php\"\n",
    "parameters = {\"request\": \"all\"}\n",
    "\n",
    "# request 'all' from steam spy and parse into dataframe\n",
    "json_data = get_request(url, parameters=parameters)\n",
    "steam_spy_all = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "\n",
    "# generate sorted app_list from steamspy data\n",
    "app_list = steam_spy_all[['appid', 'name']].sort_values('appid').reset_index(drop=True)\n",
    "\n",
    "# display first few rows\n",
    "app_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable or disable for consistency\n",
    "app_list.to_csv('Data Files/steam_app_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file to save re-running api calls. \n",
    "app_list = pd.read_csv('Data Files/steam_app_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index 32700:\n",
      "\n",
      "Exported lines 32700-32799 to steam_app_data.csv. Batch 0 time: 0:02:32 (avg: 0:02:32, remaining: 1:41:37)\n",
      "Exported lines 32800-32899 to steam_app_data.csv. Batch 1 time: 0:02:34 (avg: 0:02:33, remaining: 1:39:39)\n",
      "Exported lines 32900-32999 to steam_app_data.csv. Batch 2 time: 0:02:34 (avg: 0:02:33, remaining: 1:37:08)\n",
      "Exported lines 33000-33099 to steam_app_data.csv. Batch 3 time: 0:02:33 (avg: 0:02:33, remaining: 1:34:28)\n",
      "Exported lines 33100-33199 to steam_app_data.csv. Batch 4 time: 0:02:32 (avg: 0:02:33, remaining: 1:31:49)\n",
      "Exported lines 33200-33299 to steam_app_data.csv. Batch 5 time: 0:02:32 (avg: 0:02:33, remaining: 1:29:11)\n",
      "Exported lines 33300-33399 to steam_app_data.csv. Batch 6 time: 0:02:33 (avg: 0:02:33, remaining: 1:26:37)\n",
      "Exported lines 33400-33499 to steam_app_data.csv. Batch 7 time: 0:02:31 (avg: 0:02:33, remaining: 1:23:57)\n",
      "Exported lines 33500-33599 to steam_app_data.csv. Batch 8 time: 0:02:30 (avg: 0:02:32, remaining: 1:21:17)\n",
      "Exported lines 33600-33699 to steam_app_data.csv. Batch 9 time: 0:02:32 (avg: 0:02:32, remaining: 1:18:42)\n",
      "Exported lines 33700-33799 to steam_app_data.csv. Batch 10 time: 0:02:32 (avg: 0:02:32, remaining: 1:16:08)\n",
      "Exported lines 33800-33899 to steam_app_data.csv. Batch 11 time: 0:02:32 (avg: 0:02:32, remaining: 1:13:36)\n",
      "Exported lines 33900-33999 to steam_app_data.csv. Batch 12 time: 0:02:32 (avg: 0:02:32, remaining: 1:11:03)\n",
      "Exported lines 34000-34099 to steam_app_data.csv. Batch 13 time: 0:02:32 (avg: 0:02:32, remaining: 1:08:31)\n",
      "Exported lines 34100-34199 to steam_app_data.csv. Batch 14 time: 0:02:31 (avg: 0:02:32, remaining: 1:05:56)\n",
      "Exported lines 34200-34299 to steam_app_data.csv. Batch 15 time: 0:02:31 (avg: 0:02:32, remaining: 1:03:21)\n",
      "Exported lines 34300-34399 to steam_app_data.csv. Batch 16 time: 0:02:31 (avg: 0:02:32, remaining: 1:00:48)\n",
      "Exported lines 34400-34499 to steam_app_data.csv. Batch 17 time: 0:02:32 (avg: 0:02:32, remaining: 0:58:15)\n",
      "Exported lines 34500-34599 to steam_app_data.csv. Batch 18 time: 0:02:31 (avg: 0:02:32, remaining: 0:55:43)\n",
      "No response, waiting 10 seconds...\n",
      "Retrying.\n",
      "No response, waiting 10 seconds...\n",
      "Retrying.\n",
      "No response, waiting 10 seconds...\n",
      "Retrying.\n",
      "Exported lines 34600-34699 to steam_app_data.csv. Batch 19 time: 0:03:11 (avg: 0:02:34, remaining: 0:53:51)\n",
      "Exported lines 34700-34799 to steam_app_data.csv. Batch 20 time: 0:02:58 (avg: 0:02:35, remaining: 0:51:40)\n",
      "Exported lines 34800-34899 to steam_app_data.csv. Batch 21 time: 0:02:35 (avg: 0:02:35, remaining: 0:49:05)\n",
      "Exported lines 34900-34999 to steam_app_data.csv. Batch 22 time: 0:02:33 (avg: 0:02:35, remaining: 0:46:28)\n",
      "Exported lines 35000-35099 to steam_app_data.csv. Batch 23 time: 0:02:34 (avg: 0:02:35, remaining: 0:43:53)\n",
      "Exported lines 35100-35199 to steam_app_data.csv. Batch 24 time: 0:02:31 (avg: 0:02:35, remaining: 0:41:15)\n",
      "Exported lines 35200-35299 to steam_app_data.csv. Batch 25 time: 0:02:32 (avg: 0:02:35, remaining: 0:38:39)\n",
      "Exported lines 35300-35399 to steam_app_data.csv. Batch 26 time: 0:02:30 (avg: 0:02:34, remaining: 0:36:02)\n",
      "Exported lines 35400-35499 to steam_app_data.csv. Batch 27 time: 0:02:30 (avg: 0:02:34, remaining: 0:33:25)\n",
      "Exported lines 35500-35599 to steam_app_data.csv. Batch 28 time: 0:02:32 (avg: 0:02:34, remaining: 0:30:50)\n",
      "Exported lines 35600-35699 to steam_app_data.csv. Batch 29 time: 0:02:30 (avg: 0:02:34, remaining: 0:28:14)\n",
      "Exported lines 35700-35799 to steam_app_data.csv. Batch 30 time: 0:02:30 (avg: 0:02:34, remaining: 0:25:39)\n",
      "Exported lines 35800-35899 to steam_app_data.csv. Batch 31 time: 0:02:30 (avg: 0:02:34, remaining: 0:23:04)\n",
      "Exported lines 35900-35999 to steam_app_data.csv. Batch 32 time: 0:02:29 (avg: 0:02:34, remaining: 0:20:29)\n",
      "No response, waiting 10 seconds...\n",
      "Retrying.\n",
      "Exported lines 36000-36099 to steam_app_data.csv. Batch 33 time: 0:02:40 (avg: 0:02:34, remaining: 0:17:57)\n",
      "Exported lines 36100-36199 to steam_app_data.csv. Batch 34 time: 0:02:32 (avg: 0:02:34, remaining: 0:15:23)\n",
      "Exported lines 36200-36299 to steam_app_data.csv. Batch 35 time: 0:02:30 (avg: 0:02:34, remaining: 0:12:48)\n",
      "Exported lines 36300-36399 to steam_app_data.csv. Batch 36 time: 0:02:31 (avg: 0:02:34, remaining: 0:10:14)\n",
      "Exported lines 36400-36499 to steam_app_data.csv. Batch 37 time: 0:02:30 (avg: 0:02:34, remaining: 0:07:41)\n",
      "Exported lines 36500-36599 to steam_app_data.csv. Batch 38 time: 0:02:31 (avg: 0:02:33, remaining: 0:05:07)\n",
      "Exported lines 36600-36699 to steam_app_data.csv. Batch 39 time: 0:02:29 (avg: 0:02:33, remaining: 0:02:33)\n",
      "Exported lines 36700-36723 to steam_app_data.csv. Batch 40 time: 0:00:37 (avg: 0:02:31, remaining: 0:00:00)\n",
      "\n",
      "Processing batches complete. 4024 apps written\n"
     ]
    }
   ],
   "source": [
    "# Set file parameters\n",
    "download_path = 'Data Files'\n",
    "steam_app_data = 'steam_app_data.csv'\n",
    "steam_index = 'steam_index.txt'\n",
    "\n",
    "steam_columns = [\n",
    "    'type', 'name', 'steam_appid', 'required_age', 'is_free', 'controller_support',\n",
    "    'dlc', 'detailed_description', 'about_the_game', 'short_description', 'fullgame',\n",
    "    'supported_languages', 'header_image', 'website', 'pc_requirements', 'mac_requirements',\n",
    "    'linux_requirements', 'legal_notice', 'drm_notice', 'ext_user_account_notice',\n",
    "    'developers', 'publishers', 'demos', 'price_overview', 'packages', 'package_groups',\n",
    "    'platforms', 'metacritic', 'reviews', 'categories', 'genres', 'screenshots',\n",
    "    'movies', 'recommendations', 'achievements', 'release_date', 'support_info',\n",
    "    'background', 'content_descriptors'\n",
    "]\n",
    "\n",
    "# Overwrites last index for demonstration (would usually store highest index so can continue across sessions)\n",
    "# reset_index(download_path, steam_index)\n",
    "\n",
    "# Retrieve last index downloaded from file\n",
    "index = get_index(download_path, steam_index)\n",
    "\n",
    "# Wipe or create data file and write headers if index is 0\n",
    "prepare_data_file(download_path, steam_app_data, index, steam_columns)\n",
    "\n",
    "# Set end and chunksize for demonstration - remove to run through entire app list\n",
    "process_batches(\n",
    "    parser=parse_steam_request,\n",
    "    app_list=app_list,\n",
    "    download_path=download_path,\n",
    "    data_filename=steam_app_data,\n",
    "    index_filename=steam_index,\n",
    "    columns=steam_columns,\n",
    "    begin=index,\n",
    "    end=len(app_list),\n",
    "    batchsize=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('Data Files/steam_app_data.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set files and columns\n",
    "download_path = '../data/download'\n",
    "steamspy_data = 'steamspy_data.csv'\n",
    "steamspy_index = 'steamspy_index.txt'\n",
    "\n",
    "steamspy_columns = [\n",
    "    'appid', 'name', 'developer', 'publisher', 'score_rank', 'positive',\n",
    "    'negative', 'userscore', 'owners', 'average_forever', 'average_2weeks',\n",
    "    'median_forever', 'median_2weeks', 'price', 'initialprice', 'discount',\n",
    "    'languages', 'genre', 'ccu', 'tags'\n",
    "]\n",
    "\n",
    "reset_index(download_path, steamspy_index)\n",
    "index = get_index(download_path, steamspy_index)\n",
    "\n",
    "# Wipe data file if index is 0\n",
    "prepare_data_file(download_path, steamspy_data, index, steamspy_columns)\n",
    "\n",
    "process_batches(\n",
    "    parser=parse_steamspy_request,\n",
    "    app_list=app_list,\n",
    "    download_path=download_path, \n",
    "    data_filename=steamspy_data,\n",
    "    index_filename=steamspy_index,\n",
    "    columns=steamspy_columns,\n",
    "    begin=index,\n",
    "    end=len(app_list),\n",
    "    batchsize=100,\n",
    "    pause=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/download/steamspy_data.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
